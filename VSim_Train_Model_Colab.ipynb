{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VSim - Data Collection & Model Training\n",
        "## One-Click Setup: Collect Data + Train Model\n",
        "\n",
        "This notebook will:\n",
        "1. Install all dependencies\n",
        "2. Set up the VSim environment\n",
        "3. Collect training data from NCBI\n",
        "4. Train the viability prediction model\n",
        "5. Save the trained model\n",
        "\n",
        "**Just run all cells in order!**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install all required packages\n",
        "!pip install -q biopython numpy pandas scipy scikit-learn torch torchvision torchaudio pyyaml requests aiohttp tqdm backoff matplotlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Upload Project Files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import zipfile\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "# Check if VSim already exists (e.g., from previous run or Drive)\n",
        "if Path('/content/VSim').exists() and any(Path('/content/VSim').iterdir()):\n",
        "    print(\"✓ VSim directory already exists, skipping upload\")\n",
        "    print(f\"  Location: /content/VSim\")\n",
        "else:\n",
        "    # Option 1: Clone from GitHub (if you have a repo)\n",
        "    USE_GITHUB = False  # Set to True and provide your repo URL below\n",
        "    GITHUB_REPO = \"your-username/Project-VSim\"  # Replace with your GitHub repo\n",
        "    \n",
        "    if USE_GITHUB and GITHUB_REPO != \"your-username/Project-VSim\":\n",
        "        print(f\"Cloning from GitHub: {GITHUB_REPO}\")\n",
        "        repo_url = f\"https://github.com/{GITHUB_REPO}.git\"\n",
        "        try:\n",
        "            subprocess.run(['git', 'clone', repo_url, '/content/VSim'], check=True)\n",
        "            print(\"✓ Cloned from GitHub\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"⚠ Failed to clone from GitHub: {e}\")\n",
        "            print(\"  Please use the ZIP upload method instead\")\n",
        "    else:\n",
        "        # Option 2: Upload ZIP file\n",
        "        print(\"Please upload the Project-VSim folder as a ZIP file:\")\n",
        "        print(\"1. Zip your Project-VSim folder\")\n",
        "        print(\"2. Click 'Choose Files' below\")\n",
        "        print(\"3. Select the ZIP file\")\n",
        "        print()\n",
        "        \n",
        "        uploaded = files.upload()\n",
        "        \n",
        "        # Extract the zip file\n",
        "        extracted = False\n",
        "        for filename in uploaded.keys():\n",
        "            if filename.endswith('.zip'):\n",
        "                print(f\"\\nExtracting {filename}...\")\n",
        "                with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "                    zip_ref.extractall('/content')\n",
        "                extracted = True\n",
        "                break\n",
        "            else:\n",
        "                print(f\"⚠ {filename} is not a ZIP file. Please upload a ZIP file.\")\n",
        "        \n",
        "        # Find the Project-VSim directory\n",
        "        if Path('/content/Project-VSim').exists():\n",
        "            os.rename('/content/Project-VSim', '/content/VSim')\n",
        "            print(\"✓ Extraction complete!\")\n",
        "        elif Path('/content/VSim').exists():\n",
        "            print(\"✓ VSim directory found!\")\n",
        "        elif extracted:\n",
        "            # Look for any directory that might be it\n",
        "            dirs = [d for d in os.listdir('/content') if os.path.isdir(f'/content/{d}') and ('VSim' in d or 'Project' in d)]\n",
        "            if dirs:\n",
        "                os.rename(f'/content/{dirs[0]}', '/content/VSim')\n",
        "                print(\"✓ Extraction complete!\")\n",
        "            else:\n",
        "                print(\"⚠ Could not find Project-VSim directory after extraction\")\n",
        "                print(\"  Please check the ZIP file contents\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Setup Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Change to VSim directory\n",
        "if Path('/content/VSim').exists():\n",
        "    os.chdir('/content/VSim')\n",
        "    sys.path.insert(0, '/content/VSim')\n",
        "    print(f\"✓ Working directory: {os.getcwd()}\")\n",
        "else:\n",
        "    print(\"⚠ VSim directory not found. Please upload the Project-VSim ZIP file in Step 2.\")\n",
        "    print(\"Current directory contents:\")\n",
        "    for item in os.listdir('/content'):\n",
        "        print(f\"  - {item}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(f\"✓ GPU available: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"✓ GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"⚠ GPU not available, using CPU\")\n",
        "    print(\"⚠ For faster training, enable GPU: Runtime → Change runtime type → GPU\")\n",
        "\n",
        "# Set environment variables\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Configure Data Collection & Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===== MAXIMUM QUALITY CONFIGURATION =====\n",
        "# Optimized for maximum model quality (training time not a concern)\n",
        "\n",
        "# Data Collection Settings\n",
        "EMAIL = \"anton.valov05@gmail.com\"  # Your email for NCBI (required)\n",
        "API_KEY = \"d7e5c7978697a8c4284af0fc71ce1a2b9808\"  # NCBI API key (optional, speeds up downloads)\n",
        "\n",
        "# Training Data Settings - MAXIMUM QUALITY\n",
        "# Using full 500K dataset for best results\n",
        "TOTAL_TARGET = 500000  # Full dataset (will take ~24-48 hours for data collection)\n",
        "# For testing, you can use smaller numbers:\n",
        "# TOTAL_TARGET = 10000  # Medium dataset (will take ~1-3 hours)\n",
        "# TOTAL_TARGET = 50000  # Large dataset (will take ~5-10 hours)\n",
        "\n",
        "# Model Architecture Settings - ENHANCED\n",
        "INPUT_DIM = 1024  # Increased from 512 (larger feature space)\n",
        "HIDDEN_DIM = 512  # Increased from 256 (more capacity)\n",
        "NUM_LAYERS = 8  # Increased from 4 (deeper network)\n",
        "NUM_HEADS = 16  # Increased from 8 (more attention heads)\n",
        "\n",
        "# Training Settings - MAXIMUM QUALITY\n",
        "EPOCHS = 200  # Increased from 20 (more training for better convergence)\n",
        "BATCH_SIZE = 64  # Increased from 32 (larger batches, adjust based on GPU memory)\n",
        "LEARNING_RATE = 1e-4  # Learning rate\n",
        "WEIGHT_DECAY = 1e-5  # Weight decay for regularization\n",
        "WARMUP_EPOCHS = 10  # Warmup epochs for learning rate scheduling\n",
        "EARLY_STOPPING_PATIENCE = 20  # Early stopping patience (epochs without improvement)\n",
        "GRADIENT_CLIP_VAL = 1.0  # Gradient clipping value\n",
        "\n",
        "# Advanced Features\n",
        "USE_FOCAL_LOSS = True  # Use focal loss for better handling of class imbalance\n",
        "USE_MIXED_PRECISION = True  # Use mixed precision training (faster, uses less memory)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"MAXIMUM QUALITY CONFIGURATION\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Email: {EMAIL}\")\n",
        "print(f\"API Key: {'Provided' if API_KEY else 'Not provided'}\")\n",
        "print(f\"\\nData Collection:\")\n",
        "print(f\"  Total Target Genomes: {TOTAL_TARGET:,}\")\n",
        "print(f\"\\nModel Architecture (Enhanced):\")\n",
        "print(f\"  Input Dimension: {INPUT_DIM}\")\n",
        "print(f\"  Hidden Dimension: {HIDDEN_DIM}\")\n",
        "print(f\"  Number of Layers: {NUM_LAYERS}\")\n",
        "print(f\"  Number of Attention Heads: {NUM_HEADS}\")\n",
        "print(f\"\\nTraining Settings:\")\n",
        "print(f\"  Epochs: {EPOCHS}\")\n",
        "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"  Weight Decay: {WEIGHT_DECAY}\")\n",
        "print(f\"  Warmup Epochs: {WARMUP_EPOCHS}\")\n",
        "print(f\"  Early Stopping Patience: {EARLY_STOPPING_PATIENCE}\")\n",
        "print(f\"  Gradient Clipping: {GRADIENT_CLIP_VAL}\")\n",
        "print(f\"\\nAdvanced Features:\")\n",
        "print(f\"  Focal Loss: {USE_FOCAL_LOSS}\")\n",
        "print(f\"  Mixed Precision: {USE_MIXED_PRECISION}\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\n⚠ NOTE: This configuration is optimized for MAXIMUM QUALITY\")\n",
        "print(\"   Training will take significantly longer but produce the best model\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Collect Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import logging\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[logging.StreamHandler(sys.stdout)]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Add project root to path\n",
        "sys.path.insert(0, str(Path.cwd()))\n",
        "\n",
        "from src.vlab.data.collector import DataCollector\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"STARTING DATA COLLECTION\")\n",
        "print(\"=\"*70)\n",
        "print(f\"This will collect {TOTAL_TARGET:,} viral genomes from NCBI\")\n",
        "print(\"This may take a while depending on your target size...\")\n",
        "print(\"=\"*70)\n",
        "print()\n",
        "\n",
        "# Create collector\n",
        "collector = DataCollector(email=EMAIL, api_key=API_KEY)\n",
        "\n",
        "# Collect data\n",
        "try:\n",
        "    results = asyncio.run(collector.collect_all_data(\n",
        "        max_viable=None,  # Auto-calculate for balanced dataset\n",
        "        num_synthetic_non_viable=None,  # Auto-calculate\n",
        "        num_mutated_non_viable=None,  # Auto-calculate\n",
        "        total_target=TOTAL_TARGET\n",
        "    ))\n",
        "    \n",
        "    # Get statistics\n",
        "    stats = collector.get_data_statistics()\n",
        "    \n",
        "    # Print summary\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"DATA COLLECTION COMPLETE!\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Training Data:\")\n",
        "    print(f\"  Viable: {stats['train_viable']:,}\")\n",
        "    print(f\"  Non-viable: {stats['train_non_viable']:,}\")\n",
        "    print(f\"  Total: {stats['total_train']:,}\")\n",
        "    print(f\"\\nValidation Data:\")\n",
        "    print(f\"  Viable: {stats['val_viable']:,}\")\n",
        "    print(f\"  Non-viable: {stats['val_non_viable']:,}\")\n",
        "    print(f\"  Total: {stats['total_val']:,}\")\n",
        "    print(f\"\\nGrand Total: {stats['total']:,} genomes\")\n",
        "    print(f\"\\nData location: data/training/\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "except KeyboardInterrupt:\n",
        "    logger.error(\"\\nData collection interrupted by user\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    logger.error(f\"Data collection failed: {e}\", exc_info=True)\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Train the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import logging\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Add project root to path\n",
        "sys.path.insert(0, str(Path.cwd()))\n",
        "\n",
        "from src.vlab.training.viability_trainer import ViabilityTrainer, collect_training_data\n",
        "from src.vlab.core.config import VLabConfig\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"STARTING MODEL TRAINING\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Epochs: {EPOCHS}\")\n",
        "print(f\"Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"Device: {device}\")\n",
        "print(\"=\"*70)\n",
        "print()\n",
        "\n",
        "# Load configuration\n",
        "config = VLabConfig()\n",
        "config.use_gpu = torch.cuda.is_available()\n",
        "config.gpu_id = 0\n",
        "config.models_dir = Path('models')\n",
        "config.models_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Collect training data\n",
        "data_dir = Path('data/training')\n",
        "print(f\"Loading data from: {data_dir}\")\n",
        "\n",
        "try:\n",
        "    train_annotations, train_labels, val_annotations, val_labels = collect_training_data(data_dir)\n",
        "    \n",
        "    if not train_annotations:\n",
        "        raise ValueError(\"No training data found! Please run data collection first.\")\n",
        "    \n",
        "    print(f\"\\nLoaded {len(train_annotations)} training samples\")\n",
        "    if val_annotations:\n",
        "        print(f\"Loaded {len(val_annotations)} validation samples\")\n",
        "    \n",
        "    # Create trainer with enhanced architecture\n",
        "    print(f\"\\nCreating enhanced model with:\")\n",
        "    print(f\"  Input dim: {INPUT_DIM}, Hidden dim: {HIDDEN_DIM}\")\n",
        "    print(f\"  Layers: {NUM_LAYERS}, Heads: {NUM_HEADS}\")\n",
        "    print(f\"  Focal loss: {USE_FOCAL_LOSS}, Mixed precision: {USE_MIXED_PRECISION}\")\n",
        "    \n",
        "    trainer = ViabilityTrainer(\n",
        "        config,\n",
        "        input_dim=INPUT_DIM,\n",
        "        hidden_dim=HIDDEN_DIM,\n",
        "        num_layers=NUM_LAYERS,\n",
        "        num_heads=NUM_HEADS,\n",
        "        use_focal_loss=USE_FOCAL_LOSS,\n",
        "        use_mixed_precision=USE_MIXED_PRECISION\n",
        "    )\n",
        "    \n",
        "    # Train model with maximum quality settings\n",
        "    print(\"\\nStarting training with maximum quality configuration...\")\n",
        "    print(\"This will take a while but will produce the best possible model.\")\n",
        "    print()\n",
        "    \n",
        "    trainer.train(\n",
        "        train_annotations, train_labels,\n",
        "        val_annotations if val_annotations else None,\n",
        "        val_labels if val_labels else None,\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        weight_decay=WEIGHT_DECAY,\n",
        "        warmup_epochs=WARMUP_EPOCHS,\n",
        "        early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
        "        gradient_clip_val=GRADIENT_CLIP_VAL\n",
        "    )\n",
        "    \n",
        "    # Save final model\n",
        "    final_model_path = config.models_dir / \"viability_model_final.pth\"\n",
        "    trainer.save_model(final_model_path)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TRAINING COMPLETE!\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Model saved to: {final_model_path}\")\n",
        "    \n",
        "    # Check for best model\n",
        "    best_model_path = config.models_dir / \"viability_model_best.pth\"\n",
        "    if best_model_path.exists():\n",
        "        print(f\"Best model saved to: {best_model_path}\")\n",
        "    \n",
        "    print(\"=\"*70)\n",
        "    \n",
        "except Exception as e:\n",
        "    logger.error(f\"Training failed: {e}\", exc_info=True)\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Verify Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "# Check if model files exist\n",
        "models_dir = Path('models')\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"MODEL VERIFICATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "final_model = models_dir / \"viability_model_final.pth\"\n",
        "best_model = models_dir / \"viability_model_best.pth\"\n",
        "\n",
        "if final_model.exists():\n",
        "    size_mb = final_model.stat().st_size / (1024 * 1024)\n",
        "    print(f\"✓ Final model: {final_model} ({size_mb:.2f} MB)\")\n",
        "    \n",
        "    # Try loading the model\n",
        "    try:\n",
        "        checkpoint = torch.load(final_model, map_location='cpu')\n",
        "        print(f\"✓ Model loaded successfully\")\n",
        "        print(f\"  Model class: {checkpoint.get('model_class', 'Unknown')}\")\n",
        "        print(f\"  State dict keys: {len(checkpoint.get('model_state_dict', {}))}\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠ Error loading model: {e}\")\n",
        "else:\n",
        "    print(f\"⚠ Final model not found: {final_model}\")\n",
        "\n",
        "if best_model.exists():\n",
        "    size_mb = best_model.stat().st_size / (1024 * 1024)\n",
        "    print(f\"✓ Best model: {best_model} ({size_mb:.2f} MB)\")\n",
        "else:\n",
        "    print(f\"ℹ Best model not found (this is okay if training didn't use validation)\")\n",
        "\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Download Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Create a zip file with the trained models\n",
        "models_dir = Path('models')\n",
        "output_zip = '/tmp/vsim_trained_model.zip'\n",
        "\n",
        "if models_dir.exists():\n",
        "    print(\"Creating model archive...\")\n",
        "    \n",
        "    with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        # Add all model files\n",
        "        for model_file in models_dir.glob('*.pth'):\n",
        "            zipf.write(model_file, model_file.name)\n",
        "            print(f\"  Added: {model_file.name}\")\n",
        "    \n",
        "    # Download\n",
        "    print(f\"\\nDownloading model archive...\")\n",
        "    files.download(output_zip)\n",
        "    print(\"\\n✓ Model downloaded successfully!\")\n",
        "    print(\"\\nYou can now use this model in your VSim application.\")\n",
        "else:\n",
        "    print(\"⚠ Models directory not found. Please run training first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "✅ **Data Collection**: Complete\n",
        "✅ **Model Training**: Complete\n",
        "✅ **Model Saved**: `models/viability_model_final.pth`\n",
        "\n",
        "### Next Steps:\n",
        "1. Download the model using Step 8 above\n",
        "2. Use the model in your VSim application:\n",
        "   ```python\n",
        "   from src.vlab.viability.predictor import ViabilityPredictor\n",
        "   import torch\n",
        "   \n",
        "   model = ViabilityPredictor()\n",
        "   checkpoint = torch.load('viability_model_final.pth')\n",
        "   model.load_state_dict(checkpoint['model_state_dict'])\n",
        "   model.eval()\n",
        "   ```\n",
        "\n",
        "### Model Location:\n",
        "- Final model: `models/viability_model_final.pth`\n",
        "- Best model: `models/viability_model_best.pth` (if validation was used)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
